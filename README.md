# AIâ€‘Driven Workload & Energy Optimization for Exascale Scientific Computing

> Dissertation repository for Amos Ochiengâ€™ Bunde (MSc â†’ PhD track).  
> Theme: **Energyâ€‘aware, AIâ€‘assisted scheduling** and **carbonâ€‘aware operations** for HPC and AI training/inference at (preâ€‘)exascale.

[![CI](https://github.com/USER/REPO/actions/workflows/ci.yml/badge.svg)](https://github.com/USER/REPO/actions/workflows/ci.yml)

---

## ðŸ“Œ Problem
Exascale systems deliver unprecedented performance but at a steep **energy and carbon cost**. Traditional schedulers (FCFS/EASY) are throughputâ€‘oriented, rarely **energyâ€‘aware** or **carbonâ€‘aware**, and struggle with heterogeneous CPU/GPU clusters used for modern AI workloads.

## ðŸŽ¯ Objectives
1. **Predict** job runtime and energy using workload traces + telemetry.
2. **Optimize** scheduling via **RL/BO hybrid** policies under energy/carbon constraints.
3. **Evaluate** on real traces (PWA/Google/Alibaba) via **trace replay**.
4. **Explain** operator decisions and quantify **kWh/COâ‚‚e** tradeâ€‘offs.

## ðŸ§± Repository Structure
```
.
â”œâ”€ README.md
â”œâ”€ Makefile
â”œâ”€ requirements.txt
â”œâ”€ environment.yml
â”œâ”€ .gitignore
â”œâ”€ LICENSE
â”œâ”€ CITATION.cff
â”œâ”€ CONTRIBUTING.md
â”œâ”€ CODE_OF_CONDUCT.md
â”œâ”€ docs/
â”‚  â”œâ”€ dissertation_overview.md
â”‚  â”œâ”€ data_request_letter.md
â”‚  â”œâ”€ data_checklist.md
â”‚  â””â”€ ethics_and_privacy.md
â”œâ”€ notebooks/
â”‚  â””â”€ plot_backlog_energy_co2e.ipynb
â”œâ”€ scripts/
â”‚  â”œâ”€ nvml_logger.py
â”‚  â”œâ”€ rapl_logger.py
â”‚  â”œâ”€ carbon_intensity_gb.py
â”‚  â”œâ”€ train_energy_surrogate.py
â”‚  â””â”€ export_google_trace.sql
â”œâ”€ batsim/
â”‚  â”œâ”€ platform.xml
â”‚  â”œâ”€ config_llnl.json
â”‚  â”œâ”€ config_kth.json
â”‚  â””â”€ run_replay.sh
â”œâ”€ traces/
â”‚  â”œâ”€ pwa_llnl.swf  (placeholder â€“ drop real PWA file here)
â”‚  â””â”€ pwa_kth.swf   (placeholder â€“ drop real PWA file here)
â”œâ”€ data/
â”‚  â”œâ”€ raw/
â”‚  â””â”€ processed/
â””â”€ experiments/
   â””â”€ README.md
```

## ðŸš€ Quickstart
```bash
# 1) Clone or unzip the repo locally
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 2) Drop real PWA SWF files
# traces/pwa_llnl.swf, traces/pwa_kth.swf

# 3) Run baseline simulations (placeholder runner; wire to your batsim command)
make simulate-LLNL
make simulate-KTH

# 4) Render plots (queue backlog, energy, COâ‚‚e)
TRACE_PATH=traces/pwa_llnl.swf make plot
open notebooks/plot_report.html  # or xdg-open on Linux
```

## ðŸ§ª Reproducibility
- All analysis notebooks limited to **deterministic seeds** where applicable.
- CI checks for style, notebook execution, and basic linting (see `.github/workflows/ci.yml`).

## ðŸ”’ Data & Ethics
- No PII; user/project/node identifiers are **hashed**.  
- Telemetry may be **aggregated** (1â€“60 s).  
- Results reported with **kâ€‘anonymity** and reviewed by providers preâ€‘publication.  
- See `docs/ethics_and_privacy.md` and `docs/data_checklist.md`.

## ðŸ”— Public Datasets (for immediate use)
- **PWA SWF traces**: https://www.cs.huji.ac.il/labs/parallel/workload/  
- **Google Cluster 2019**: BigQuery public dataset (export with `scripts/export_google_trace.sql`)  
- **Carbon intensity (GB)**: https://api.carbonintensity.org.uk/

## ðŸ“£ Citation
If you use this repo, please cite (see `CITATION.cff`).

## ðŸ“œ License
MIT (see `LICENSE`).

---

### GitHub Setup
```bash
git init
git add .
git commit -m "Initial commit: dissertation repo skeleton"
git branch -M main
git remote add origin git@github.com:<your-user>/<your-repo>.git
git push -u origin main
```
